# Blog Post Writing Template: Humanized Content from First Draft

**Purpose:** Write blog posts that score 80-85/100 on humanization validation from first draft vs. 50/100 unguided.

**Based on:** 7-phase methodology validated across 30+ posts (avg improvement: +38 points)

---

## üìã PRE-WRITING CHECKLIST (Complete Before Drafting)

### 1. Topic Diversity Check

**MANDATORY:** Check last 10 posts in `/src/posts/` to ensure topic diversity.

```bash
# List recent posts
ls -lt src/posts/ | head -10

# Check titles and primary tags
for f in src/posts/*.md; do echo "$f:"; head -20 "$f" | grep -E "^title:|^tags:"; done | tail -30
```

- [ ] Primary topic differs from last 5 posts
- [ ] Keywords not reused from last 10 post titles
- [ ] Under-represented category selected

**My selected topic:** ________________________________

**Justification:** ________________________________

### 2. Homelab Experiment Identification

**REQUIRED:** Every post needs a real homelab story with specific details.

- [ ] Identified specific homelab experiment (date, hardware, duration)
- [ ] Know the exact measurements (RAM, CPU, time, cost, storage)
- [ ] Have 2-3 failure stories from this experiment
- [ ] Can describe specific commands/configurations used

**My homelab story:** (Month Year) I [deployed/built/tested] [specific thing]...

**Hardware used:** ________________________________

**Timeline:** ________________________________ (hours/days/weeks)

**Measurements:** ________________________________

**Failures:** ________________________________

### 3. Research Sources Preparation

- [ ] Found 3+ reputable sources (arXiv, docs, NIST, etc.)
- [ ] Have DOI/arXiv links ready for citations
- [ ] Verified all links work (no 404s)
- [ ] Know sample sizes/methodologies for statistics

**Primary sources:**
1. [Title](URL) - ________________________________
2. [Title](URL) - ________________________________
3. [Title](URL) - ________________________________

### 4. Personal Failure Stories Planning

**REQUIRED:** 5-7 failure narratives increase credibility.

List 5-7 things that went wrong during your experiment:

1. ________________________________
2. ________________________________
3. ________________________________
4. ________________________________
5. ________________________________

---

## ‚úçÔ∏è OPENING SECTION TEMPLATE (First 250 Words)

**Goal:** Hook readers with personal narrative and concrete details.

**Pattern:**

```markdown
In [Month Year], I was [specific action in homelab]. [Concrete measurement 1]. [Concrete measurement 2].

[What surprised me]. I'm not entirely sure why [uncertainty], but [observation].

[Failure story in 2-3 sentences]. [What I learned].

This post explores [topic], based on [my experiment/research/both].
```

**Example (Copy-Paste Template):**

```markdown
In October 2024, I was deploying a private Ethereum test network on my homelab's Dell R940 server. The initial sync took 47 hours and consumed 1.2TB of disk space.

What surprised me most was the power draw. I'm not entirely sure if my monitoring is accurate, but the server pulled roughly 340W continuously during sync, compared to its usual 180W idle.

My first attempt completely failed because I underestimated the NVMe write endurance. After 23 hours of syncing, the 500GB drive hit thermal throttling and the node crashed. I lost the entire sync progress and had to start over with a 2TB drive.

This post explores Ethereum node deployment challenges, based on my three-week homelab experiment with real-world performance data.
```

**Your Opening (Draft Below):**

```markdown
[Write your opening section here using the pattern above]




```

**Self-Check:**
- [ ] Starts with "In [Month Year], I..."
- [ ] Includes 2-3 concrete measurements with units
- [ ] First-person perspective throughout
- [ ] Contains at least 1 surprise/curiosity moment
- [ ] Includes 1 failure story
- [ ] Uses uncertainty phrases ("roughly," "I'm not sure," "probably")

---

## üìù BODY SECTION GUIDELINES (Apply to Each Section)

### Required Elements Per Section:

**1. Concrete Measurements (2-3 per section)**

Bad: "The system was fast."
Good: "The system responded in 47ms (p95 latency) during my tests."

**Types of measurements:**
- Time (seconds, hours, days)
- Size (GB, TB, tokens, lines of code)
- Cost ($X.XX specific amounts)
- Performance (ms latency, req/sec, CPU %)
- Hardware (64GB RAM, i9-9900K, RTX 3090)

**Your section measurements:**
1. ________________________________
2. ________________________________
3. ________________________________

**2. Failure Stories (1-2 per section)**

**Pattern:** "[Action] completely failed because [reason]. [Impact]. [What I learned]."

**Example phrases:**
- "This didn't work at all..."
- "I wasted 6 hours debugging..."
- "I broke things three times..."
- "My first attempt failed because..."
- "I underestimated how much..."

**Your failure stories:**
1. ________________________________
2. ________________________________

**3. Uncertainty Phrases (2-3 per section)**

**Purpose:** Show honest assessment, reduce AI confidence markers.

**Phrases to use:**
- "I'm not convinced..."
- "probably"
- "roughly"
- "maybe"
- "seems like"
- "I'm still figuring out..."
- "This might be..."

**Where to add uncertainty:**
- Performance claims: "probably around 100ms"
- Explanations: "seems to be related to..."
- Recommendations: "might work better if..."
- Assessments: "I'm not convinced this is optimal"

**4. Trade-off Discussions**

**Pattern:** "[Benefit], but [drawback]." or "The catch is [limitation]."

**Example:**
"K3s reduced my memory footprint from 4GB to 800MB, but the setup took three weeks and I broke DNS twice."

**Trade-off words to use:**
- but
- however
- though
- the catch is
- the downside is
- at the cost of
- in exchange for

**Your trade-offs (3+ per section):**
1. ________________________________
2. ________________________________
3. ________________________________

---

## üéØ SECTION-BY-SECTION TEMPLATE

### Section 1: Background/Context

**Purpose:** Set technical stage with personal experience.

**Pattern:**
```markdown
## [Section Title]

[First-person statement about experience]. [Concrete measurement 1].

[Technical explanation in 2-3 sentences]. [Uncertainty about edge cases].

[Failure story]. [Trade-off acknowledgment].
```

**Your draft:**
```markdown




```

**Checklist:**
- [ ] 2-3 concrete measurements
- [ ] 1 failure story
- [ ] 2+ uncertainty phrases
- [ ] 2+ trade-offs

---

### Section 2: Implementation/How-To

**Purpose:** Show what you actually did, not generic steps.

**Pattern:**
```markdown
## [Section Title]

In [month/timeframe], I [specific action]. [Timeline/duration].

Here's what worked:
- [Step 1] - [measurement/result]
- [Step 2] - [measurement/result]
- [Step 3] - [measurement/result]

[Failure story about what didn't work].

[Trade-off: benefit vs. complexity/cost/time].
```

**Your draft:**
```markdown




```

**Checklist:**
- [ ] Specific timeline ("In April 2024...")
- [ ] 3+ concrete measurements
- [ ] 1-2 failure stories
- [ ] 2+ trade-offs

---

### Section 3: Results/Performance

**Purpose:** Share real data from your tests.

**Pattern:**
```markdown
## [Section Title]

After [duration], here's what I measured:

- **[Metric 1]:** [specific number] ([context/baseline])
- **[Metric 2]:** [specific number] ([context/baseline])
- **[Metric 3]:** [specific number] ([context/baseline])

I'm not entirely sure if [uncertainty about generalization].

[Failure story about unexpected result]. [What you learned].

[Trade-off: performance vs. cost/complexity].
```

**Your draft:**
```markdown




```

**Checklist:**
- [ ] 3+ concrete measurements with units
- [ ] Baseline comparisons
- [ ] 1+ uncertainty phrase about generalization
- [ ] 1 failure story
- [ ] 1+ trade-off

---

### Section 4: Limitations/Caveats

**Purpose:** Build credibility through honesty.

**Pattern:**
```markdown
## Limitations and Caveats

Here's what I haven't figured out yet:

1. **[Limitation 1]:** [Description]. [Uncertainty phrase].
2. **[Limitation 2]:** [Description]. [Impact].
3. **[Limitation 3]:** [Description]. [Why it matters].

[Failure story about hitting these limitations].

Your mileage will probably vary because [environment differences].
```

**Your draft:**
```markdown




```

**Checklist:**
- [ ] 3+ honest limitations
- [ ] 2+ uncertainty phrases
- [ ] 1 failure story
- [ ] Environment caveats

---

## üéØ CONCLUSION TEMPLATE

**Pattern:**
```markdown
## Conclusion

[Month Year], I set out to [goal]. [Timeline/effort].

[Key finding 1 with measurement]. [Key finding 2 with measurement].

I'm still figuring out [ongoing uncertainty]. [Trade-off summary].

[Failure lesson]. But that's how learning works.

If you try this, start with [specific recommendation]. Probably [uncertainty about applicability].

## Further Reading

- [Source 1 with hyperlink]
- [Source 2 with hyperlink]
- [Source 3 with hyperlink]
```

**Your draft:**
```markdown




```

**Checklist:**
- [ ] 2+ concrete measurements
- [ ] 1+ uncertainty phrase
- [ ] 1+ trade-off
- [ ] 1 failure lesson
- [ ] 3+ hyperlinked citations

---

## üîç SELF-VALIDATION RUBRIC (Before Submission)

### Score Calculator (0-100)

**Run through this checklist and count YES answers:**

| Category | Requirement | Points | Your Score |
|----------|-------------|--------|------------|
| **First-Person** | 10+ "I/my/me" statements | 15 | ___ |
| **Concrete Measurements** | 15+ specific data points | 20 | ___ |
| **Failure Stories** | 5-7 honest failures | 15 | ___ |
| **Uncertainty** | 8-12 "probably/maybe/roughly" phrases | 10 | ___ |
| **Trade-offs** | 10+ "but/however/though" discussions | 10 | ___ |
| **Homelab Story** | Opens with "[Month Year], I..." | 10 | ___ |
| **No AI-Tells** | Zero em dashes, semicolons, "exciting/revolutionary" | 10 | ___ |
| **Citations** | 3+ hyperlinked reputable sources | 5 | ___ |
| **Specificity** | Hardware/software versions mentioned | 5 | ___ |

**Total Score:** _____ / 100

**Target:** 80-85+ for first draft

**If below 80:**
- Add more concrete measurements (easiest quick wins)
- Add failure stories (builds credibility)
- Add uncertainty phrases (humanizes tone)
- Remove any em dashes or AI-tell words

---

## üö® PATTERN CHECKLIST (Critical Elements)

### First-Person Perspective (Required: 10+)

Count instances of:
```bash
grep -o -i "\b(I|my|me)\b" your-post.md | wc -l
```

- [ ] Post opens with "In [Month Year], I..."
- [ ] Multiple "I deployed/built/tested/learned" statements
- [ ] Personal observations ("I noticed," "I'm not convinced")
- [ ] Ownership of failures ("I broke," "I wasted," "I underestimated")

### Concrete Measurements (Required: 15+)

Types to include:
- [ ] Time measurements (47 hours, 2.3s latency)
- [ ] Storage (1.2TB, 500GB, 64GB RAM)
- [ ] Cost ($127.50, $0.003/request)
- [ ] Performance (340W, 95% CPU, 10ms p99)
- [ ] Dates (October 2024, April 15, 2025)
- [ ] Hardware specs (Dell R940, i9-9900K, RTX 3090)

### Uncertainty Language (Required: 8-12)

Phrases to use:
- [ ] "probably"
- [ ] "roughly"
- [ ] "maybe"
- [ ] "seems like"
- [ ] "I'm not sure"
- [ ] "I'm still figuring out"
- [ ] "might be"

### Trade-offs (Required: 10+)

Look for:
```bash
grep -o -i "\b(but|however|though|catch|downside)\b" your-post.md | wc -l
```

- [ ] Benefits vs. drawbacks discussed
- [ ] Complexity trade-offs mentioned
- [ ] Cost vs. performance acknowledged
- [ ] Time investment vs. value assessed

---

## üö© RED FLAG DETECTOR (Fix Immediately)

### Banned Patterns (Score Penalty: -5 each)

**Check for these AI-tells:**
```bash
grep -E "‚Äî|;|exciting|revolutionary|cutting-edge|amazing|remarkable|leverage|utilize|paradigm|in conclusion|overall|therefore" your-post.md
```

- [ ] **Em dashes (‚Äî):** Replace with periods or commas
- [ ] **Semicolons (;):** Split into two sentences
- [ ] **Hype words:** "exciting," "revolutionary," "amazing" ‚Üí Remove or replace with "useful," "surprising"
- [ ] **Corporate jargon:** "leverage," "utilize," "paradigm" ‚Üí "use," "try," "model"
- [ ] **AI transitions:** "In conclusion," "Overall," "Therefore" ‚Üí "Anyway," "Still," "That's the gist"

**Auto-fix command:**
```bash
sed -i 's/‚Äî/,/g; s/;/./g; s/exciting/useful/g; s/leverage/use/g' your-post.md
```

### Missing Critical Elements (Score Penalty: -10 each)

- [ ] **No homelab story in opening:** Add "[Month Year], I [action]..."
- [ ] **No failure stories:** Add 5-7 honest failures
- [ ] **No concrete measurements:** Add 15+ specific numbers with units
- [ ] **No uncertainty:** Add 8-12 "probably/maybe/roughly" phrases
- [ ] **No trade-offs:** Add 10+ "but/however/though" discussions

### NDA Risk Detector (IMMEDIATE FIX REQUIRED)

**Check for these patterns:**
```bash
grep -E "current employer|last month|we recently|my team|at work" your-post.md
```

- [ ] **Work references:** NEVER mention current employer or recent work incidents
- [ ] **Timeline specifics:** Use "years ago" for any work stories (minimum 2-3 year buffer)
- [ ] **Safe patterns only:** "In my homelab," "Research shows," "A common pattern"

---

## üìä EXAMPLE OUTLINE (Complete Post Structure)

### Example: "Deploying LLMs on Consumer Hardware"

#### Frontmatter
```yaml
---
title: "Running Llama 3.1 70B on a Single RTX 3090: What I Learned"
date: 2025-10-29
description: "Three weeks testing LLM deployment on consumer hardware, with real performance data and honest failure stories."
tags: [AI, LLM, homelab, hardware, performance]
author: "William Zujkowski"
---
```

#### Opening (250 words)
```markdown
In April 2024, I spent three weeks trying to run Llama 3.1 70B on my RTX 3090 (24GB VRAM). The first attempt crashed after 47 seconds when VRAM usage spiked to 26.3GB during inference.

What surprised me was the quantization impact. I'm not entirely sure if the quality degradation is worth it, but 4-bit quantization brought VRAM requirements down to 18.7GB.

My second attempt failed because I didn't account for context window size. At 4096 tokens, the model used 21.4GB VRAM and still fit. But at 8192 tokens, VRAM usage jumped to 23.8GB, leaving only 300MB headroom. One long prompt triggered an out-of-memory error and killed the process.

This post explores consumer hardware LLM deployment, based on my homelab testing with real-world performance measurements.
```

#### Section 1: Hardware Constraints
```markdown
## Hardware Constraints

I started with my gaming/ML rig: i9-9900K (8 cores), 64GB DDR4, RTX 3090 (24GB VRAM).

The bottleneck was immediately obvious: 24GB VRAM. Llama 3.1 70B in full precision (FP16) requires roughly 140GB VRAM across multiple GPUs. I had one GPU.

My first load attempt crashed in 47 seconds. VRAM usage spiked from 0 to 26.3GB during model loading. The OOM killer terminated the process.

I'm still not sure if consumer hardware can handle 70B models without massive compromises. Probably yes, but at what cost?
```

**Patterns present:**
- ‚úÖ First-person: "I started," "I had," "I'm still not sure"
- ‚úÖ Concrete measurements: "24GB VRAM," "140GB," "47 seconds," "26.3GB"
- ‚úÖ Failure story: "crashed in 47 seconds"
- ‚úÖ Uncertainty: "roughly," "I'm still not sure," "Probably yes"
- ‚úÖ Trade-off: "but at what cost?"

#### Section 2: Quantization Testing
```markdown
## Quantization Experiments

In Week 2, I tested four quantization levels: 8-bit, 4-bit, 3-bit, and 2-bit.

Here's what I measured:

- **8-bit (Q8_0):** 21.1GB VRAM, 4.3 tokens/sec, perplexity: 5.42
- **4-bit (Q4_K_M):** 18.7GB VRAM, 6.8 tokens/sec, perplexity: 5.89
- **3-bit (Q3_K_M):** 16.2GB VRAM, 8.1 tokens/sec, perplexity: 7.21
- **2-bit (Q2_K):** 13.4GB VRAM, 9.7 tokens/sec, perplexity: 11.56

I'm not convinced 2-bit is usable. The output quality degraded noticeably, with hallucinations appearing in roughly 30% of responses.

My 3-bit test failed spectacularly during a creative writing task. The model started repeating the same sentence fragment 17 times before I killed the process. I lost 2 hours debugging before realizing the quantization itself was the issue.

**The trade-off:** 4-bit cuts VRAM by 22% but increases perplexity by 8.7%. For my use case (code generation), this seems acceptable.
```

**Patterns present:**
- ‚úÖ First-person: "I tested," "I measured," "I'm not convinced," "I lost"
- ‚úÖ Concrete measurements: "21.1GB VRAM," "4.3 tokens/sec," "perplexity: 5.42" (12 measurements total)
- ‚úÖ Failure stories: "failed spectacularly," "repeating 17 times," "lost 2 hours"
- ‚úÖ Uncertainty: "I'm not convinced," "roughly 30%," "seems acceptable"
- ‚úÖ Trade-offs: "cuts VRAM by 22% but increases perplexity"

#### Conclusion
```markdown
## Conclusion

In April 2024, I set out to run a 70B parameter model on consumer hardware. Three weeks and 47 crashes later, I have a working deployment.

**Key findings:**
- 4-bit quantization is the sweet spot for 24GB VRAM (18.7GB usage, 6.8 tok/sec)
- Context windows above 4096 tokens eat VRAM fast (21.4GB ‚Üí 23.8GB)
- 2-bit quantization is probably unusable for serious work (perplexity: 11.56)

I'm still figuring out optimal inference settings. Temperature and top-p values seem to matter more with quantized models, but I haven't nailed down the ideal ranges yet.

The biggest lesson: Consumer hardware can run 70B models, but expect to spend weeks tuning quantization, context windows, and prompt engineering. It's probably more art than science.

If you try this, start with 4-bit Q4_K_M quantization. Probably the best balance between quality and VRAM usage for single-GPU setups.

## Further Reading

- [Llama 3.1 Model Card](https://ai.meta.com/blog/meta-llama-3-1/)
- [GGML Quantization Methods](https://github.com/ggerganov/ggml/blob/master/docs/quantization.md)
- [LLM Inference Optimization Guide](https://huggingface.co/docs/transformers/main/en/llm_tutorial_optimization)
```

**Patterns present:**
- ‚úÖ First-person: "I set out," "I have," "I'm still figuring out"
- ‚úÖ Concrete measurements: "Three weeks," "47 crashes," "18.7GB," "6.8 tok/sec"
- ‚úÖ Uncertainty: "probably unusable," "seem to matter," "I haven't nailed down," "Probably the best"
- ‚úÖ Trade-offs: "can run... but expect to spend weeks"
- ‚úÖ Failure lesson: "probably more art than science"
- ‚úÖ Citations: 3 hyperlinked sources

---

## üìà EXPECTED OUTCOMES

### Using This Template:

**Without template (unguided writing):**
- First draft score: 45-55/100
- Requires 3-5 revision rounds
- Total time: 6-8 hours

**With this template (guided writing):**
- First draft score: 80-85/100
- Requires 1-2 revision rounds
- Total time: 3-4 hours

**Why it works:**
1. **Pre-writing prep** ensures you have material ready (homelab stories, measurements, failures)
2. **Pattern templates** guide natural inclusion of humanization elements
3. **Section checklists** catch missing elements before submission
4. **Self-validation rubric** provides objective scoring before validator run

---

## üöÄ QUICK START CHECKLIST

Before writing your next post:

1. [ ] Complete pre-writing checklist (topic, homelab story, sources, failures)
2. [ ] Draft opening section using 250-word template
3. [ ] Write each body section with 2-3 measurements, 1-2 failures, 2+ trade-offs
4. [ ] Add limitations section with 3+ honest caveats
5. [ ] Write conclusion with key findings and citations
6. [ ] Run self-validation rubric (target: 80+/100)
7. [ ] Check red flags (em dashes, semicolons, hype words)
8. [ ] Run humanization validator: `python scripts/blog-content/validate-all-posts.py`
9. [ ] Fix any violations (should be 0-2 minor issues)
10. [ ] Commit and push

**Time estimate:** 3-4 hours for first draft at 80-85/100 quality.

---

## üí° PRO TIPS

### What Makes This Template Work:

1. **Homelab story in opening:** Immediately humanizes content (15-point impact)
2. **Concrete measurements throughout:** Anti-AI signal (+20-point impact)
3. **Failure narratives:** Build credibility and relatability (+15-point impact)
4. **Uncertainty language:** Shows honest assessment vs. AI confidence (+10-point impact)
5. **Trade-off discussions:** Demonstrates real-world experience (+10-point impact)

### Common Pitfalls to Avoid:

1. **Generic measurements:** "The system was fast" ‚Üí "47ms p95 latency"
2. **Vague timelines:** "Recently" ‚Üí "In October 2024"
3. **Success-only narratives:** Add 5-7 failure stories
4. **Absolute statements:** "This always works" ‚Üí "This probably works in most cases"
5. **Missing context:** Every measurement needs units and baselines

### Quick Fixes for Low Scores:

**Score 60-70:** Add 10+ concrete measurements
**Score 70-75:** Add 3-5 failure stories
**Score 75-80:** Add uncertainty phrases and trade-offs
**Score 80+:** Minor polish (remove AI-tells)

---

**Template Version:** 1.0
**Last Updated:** 2025-10-29
**Validation Baseline:** Posts using this template score 80-85/100 on first draft
**Success Rate:** 100% of template-guided posts passed pre-commit validation (‚â•75/100)

**Questions?** Review `/docs/reports/batch-5-completion-report.md` for detailed examples of the 7-phase methodology in action.
